import os
import re
import time
import pandas as pd
from googleapiclient.discovery import build
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

API_KEY = os.getenv('YOUTUBE_API_KEY')
CHANNEL_ID = os.getenv('CHANNEL_ID')
PLAYLISTS_CSV = os.getenv('PLAYLISTS_CSV')
MAIN_DATA_CSV = os.getenv('MAIN_DATA_CSV')
CATEGORIZE_CSV = os.getenv('CATEGORIZE_CSV')
FILTERED_DATA_CSV = os.getenv('FILTERED_DATA_CSV')

# ----------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ----------------------------------------

def extract_number_from_title(title):
    """ã‚¿ã‚¤ãƒˆãƒ«ã®æœ«å°¾ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡ºï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° -1ï¼‰"""
    match = re.search(r'(\d+)$', title)
    return int(match.group(1)) if match else -1


# ----------------------------------------
# YouTube API æ“ä½œ
# ----------------------------------------

def get_playlists(api_key, channel_id):
    """YouTube APIã‹ã‚‰ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—"""
    youtube = build('youtube', 'v3', developerKey=api_key)
    playlists = []
    nextPageToken = None

    while True:
        request = youtube.playlists().list(
            part='snippet,contentDetails',
            channelId=channel_id,
            maxResults=50,
            pageToken=nextPageToken
        )
        response = request.execute()

        for item in response['items']:
            playlists.append({
                'title': item['snippet']['title'],
                'playlist_id': item['id'],
                'video_count': item['contentDetails']['itemCount']
            })

        nextPageToken = response.get('nextPageToken')
        if not nextPageToken:
            break

    return playlists


# ----------------------------------------
# CSVæ“ä½œ
# ----------------------------------------

def update_csv_counts(csv_path, youtube_playlists):
    """CSVå†…ã®countåˆ—ã‚’YouTubeä¸Šã®å®Ÿæ•°ã§æ›´æ–°"""
    df = pd.read_csv(csv_path)
    df['playlist_id'] = df['url'].apply(lambda url: url.split('list=')[1] if 'list=' in url else '')
    playlist_map = {p['playlist_id']: p['video_count'] for p in youtube_playlists}

    def update_count(row):
        return playlist_map.get(row['playlist_id'], row['count'])  # ä¸€è‡´ã™ã‚‹IDãŒãªã‘ã‚Œã°ç¾çŠ¶ç¶­æŒ

    df['count'] = df.apply(update_count, axis=1)
    df.drop(columns=['playlist_id'], inplace=True)
    df.to_csv(csv_path, index=False)

    print('âœ… count ã‚’æ›´æ–°ã—ã¾ã—ãŸ')


# ----------------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ¯”è¼ƒå‡¦ç†
# ----------------------------------------

def fetch_playlist_data(playlist):
    """
    ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå†…ã®å‹•ç”»æƒ…å ±ã‚’å–å¾—ã—ã€MAIN_DATA_CSVã«è¿½è¨˜ã™ã‚‹ã€‚
    CSVåˆ—: id, title, channel, date, url, playlist
    """
    youtube = build('youtube', 'v3', developerKey=API_KEY)
    playlist_id = playlist['playlist_id']
    playlist_title = playlist['title']

    videos = []
    nextPageToken = None
    while True:
        request = youtube.playlistItems().list(
            part='snippet',
            playlistId=playlist_id,
            maxResults=50,
            pageToken=nextPageToken
        )
        response = request.execute()
        time.sleep(1)  # APIã‚¢ã‚¯ã‚»ã‚¹é–“éš”ã‚’ç©ºã‘ã‚‹

        for item in response['items']:
            snippet = item['snippet']
            video_id = snippet['resourceId']['videoId']
            video_title = snippet['title']
            channel_title = snippet['videoOwnerChannelTitle'] if 'videoOwnerChannelTitle' in snippet else snippet['channelTitle']
            published_at = snippet['publishedAt']
            video_url = f'https://www.youtube.com/watch?v={video_id}'

            videos.append({
                'title': video_title,
                'channel': channel_title,
                'date': published_at,
                'url': video_url,
                'playlist': playlist_title
            })

        nextPageToken = response.get('nextPageToken')
        if not nextPageToken:
            break

    # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã¨idä»˜ä¸
    if os.path.exists(MAIN_DATA_CSV):
        df_existing = pd.read_csv(MAIN_DATA_CSV)
        max_id = df_existing['id'].max() if not df_existing.empty else 0
    else:
        df_existing = pd.DataFrame()
        max_id = 0

    # æ–°è¦å‹•ç”»ãƒ‡ãƒ¼ã‚¿DataFrameä½œæˆ
    df_new = pd.DataFrame(videos)
    df_new.insert(0, 'id', range(max_id + 1, max_id + 1 + len(df_new)))

    # æ—¢å­˜ã¨æ–°è¦ã‚’çµåˆã—ä¿å­˜ï¼ˆè¿½è¨˜ï¼‰
    if not df_existing.empty:
        df_combined = pd.concat([df_existing, df_new], ignore_index=True)
    else:
        df_combined = df_new

    df_combined.to_csv(MAIN_DATA_CSV, index=False)

    print(f"âœ… ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã€{playlist_title}ã€ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’ {MAIN_DATA_CSV} ã«è¿½è¨˜ã—ã¾ã—ãŸï¼ˆ{len(df_new)}ä»¶ï¼‰")

    if os.path.exists(PLAYLISTS_CSV):
        df_playlists = pd.read_csv(PLAYLISTS_CSV)
    else:
        df_playlists = pd.DataFrame(columns=['title', 'playlist_id', 'video_count'])

    # video_count ã¯ä»Šå›å–å¾—å‹•ç”»æ•°
    video_count = len(videos)

    # æ—¢å­˜ã«ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒã‚ã‚Œã°æ›´æ–°ã€ãªã‘ã‚Œã°è¿½åŠ 
    if playlist_id in df_playlists['playlist_id'].values:
        df_playlists.loc[df_playlists['playlist_id'] == playlist_id, ['title', 'video_count']] = [playlist_title, video_count]
    else:
        df_playlists = pd.concat([df_playlists, pd.DataFrame([{
            'title': playlist_title,
            'playlist_id': playlist_id,
            'video_count': video_count
        }])], ignore_index=True)

    df_playlists.to_csv(PLAYLISTS_CSV, index=False)

    print(f"âœ… ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæƒ…å ±ã‚’ {PLAYLISTS_CSV} ã«æ›´æ–°ã—ã¾ã—ãŸ")



def identify_and_fetch_target_playlists(youtube_playlists, csv_path):
    """
    CSVã«å­˜åœ¨ã—ãªã„ã€ã¾ãŸã¯ count ãŒä¸€è‡´ã—ãªã„ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è¡Œã†
    """
    df = pd.read_csv(csv_path)
    df['playlist_id'] = df['url'].apply(lambda url: url.split('list=')[1] if 'list=' in url else '')
    csv_map = df.set_index('playlist_id').to_dict(orient='index')

    for playlist in youtube_playlists:
        pid = playlist['playlist_id']
        youtube_count = playlist['video_count']
        csv_entry = csv_map.get(pid)

        if csv_entry is None:
            print(f"ğŸ†• CSVã«å­˜åœ¨ã—ãªã„ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {playlist['title']}")
            fetch_playlist_data(playlist)
        elif youtube_count != csv_entry['count']:
            print(f"âš ï¸ countä¸ä¸€è‡´: {playlist['title']}ï¼ˆCSV: {csv_entry['count']} â†’ YouTube: {youtube_count}ï¼‰")
            fetch_playlist_data(playlist)


def check_csv_latest_playlist(youtube_playlists, csv_path):
    """CSVä¸Šã®æœ€æ–°ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒYouTubeã¨ä¸€è‡´ã™ã‚‹ã‹ç¢ºèª"""
    df = pd.read_csv(csv_path)
    df['number'] = df['title'].apply(extract_number_from_title)
    latest_row = df.loc[df['number'].idxmax()]
    latest_title = latest_row['title']
    csv_count = latest_row['count']

    print(f"ğŸ—‚ï¸ CSVä¸Šã®æœ€æ–°ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {latest_title}ï¼ˆcount: {csv_count}ï¼‰")

    match = next((p for p in youtube_playlists if p['title'] == latest_title), None)
    if not match:
        print('âš ï¸ YouTubeä¸Šã«åŒåã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return

    youtube_count = match['video_count']
    if csv_count == youtube_count:
        print('âœ… CSVã¨YouTubeã®å‹•ç”»æ•°ã¯ä¸€è‡´ã—ã¦ã„ã¾ã™')
    else:
        print(f'âŒ ä¸ä¸€è‡´ã§ã™ï¼ˆCSV: {csv_count}, YouTube: {youtube_count}ï¼‰')

def clean_and_sort_main_data():
    if not os.path.exists(MAIN_DATA_CSV):
        print(f"âŒ {MAIN_DATA_CSV} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    df = pd.read_csv(MAIN_DATA_CSV)
    before_count = len(df)

    # é‡è¤‡å‰Šé™¤ï¼ˆURLåŸºæº–ï¼‰
    df = df.drop_duplicates(subset='url')

    # æ–°ã—ã„é †ï¼ˆæœ€æ–°ãŒä¸Šï¼‰ã«ä¸¦ã³æ›¿ãˆ
    df = df.sort_values(by='date', ascending=False).reset_index(drop=True)

    # æ—¢å­˜ã® id åˆ—ãŒã‚ã‚Œã°å‰Šé™¤
    if 'id' in df.columns:
        df = df.drop(columns=['id'])

    # id ã‚’å†ä»˜ä¸ï¼ˆ1ã‚¹ã‚¿ãƒ¼ãƒˆï¼‰
    df.insert(0, 'id', range(1, len(df) + 1))

    # ä¿å­˜
    df.to_csv(MAIN_DATA_CSV, index=False)

    after_count = len(df)
    print(f"ğŸ§¹ main-data.csv ã‚’æ•´ç†ã—ã¾ã—ãŸï¼ˆ{before_count} â†’ {after_count}ä»¶ã€æœ€æ–°é †ãƒ»é‡è¤‡å‰Šé™¤ï¼‰")


def filter_checked_channels(output_csv=FILTERED_DATA_CSV, verbose=True):
    """checkãŒ1ã®ãƒãƒ£ãƒ³ãƒãƒ«ã«è©²å½“ã™ã‚‹å‹•ç”»ã®ã¿ã‚’æŠ½å‡ºã—ã€CSVã«å‡ºåŠ›"""
    if not os.path.exists(MAIN_DATA_CSV) or not os.path.exists(CATEGORIZE_CSV):
        print("âŒ å¿…è¦ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    df_main = pd.read_csv(MAIN_DATA_CSV)
    df_categorize = pd.read_csv(CATEGORIZE_CSV)

    # check == 1 ã®ãƒãƒ£ãƒ³ãƒãƒ«ã‚’æŠ½å‡º
    checked_channels = df_categorize[df_categorize['check'] == 1]['channel'].unique()

    # mainãƒ‡ãƒ¼ã‚¿ã‹ã‚‰è©²å½“ãƒãƒ£ãƒ³ãƒãƒ«ã®ã¿æŠ½å‡º
    df_filtered = df_main[df_main['channel'].isin(checked_channels)]

    # çµæœã‚’CSVã«å‡ºåŠ›
    df_filtered.to_csv(output_csv, index=False)

    if verbose:
        print(f"âœ… check=1 ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®å‹•ç”»ã‚’ {output_csv} ã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆ{len(df_filtered)}ä»¶ï¼‰")

    return df_filtered

# ----------------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ----------------------------------------

def main():
    print('â–¶ï¸ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå–å¾—ä¸­...')
    playlists = get_playlists(API_KEY, CHANNEL_ID)

    print('ğŸ” CSVã¨ã®æ¯”è¼ƒãƒ»ãƒ‡ãƒ¼ã‚¿å–å¾—å¯¾è±¡ã‚’åˆ¤å®šä¸­...')
    identify_and_fetch_target_playlists(playlists, PLAYLISTS_CSV)

    clean_and_sort_main_data()
    filter_checked_channels()


if __name__ == '__main__':
    # main()
    filter_checked_channels()
