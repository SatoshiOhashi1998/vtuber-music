import os
import re
import time
import shutil
import pandas as pd
from googleapiclient.discovery import build
from dotenv import load_dotenv

# ç’°å¢ƒå¤‰æ•°ã®èª­ã¿è¾¼ã¿
load_dotenv()

API_KEY = os.getenv('YOUTUBE_API_KEY')
CHANNEL_ID = os.getenv('CHANNEL_ID')
PLAYLISTS_CSV = os.getenv('PLAYLISTS_CSV')
MAIN_DATA_CSV = os.getenv('MAIN_DATA_CSV')
CATEGORIZE_CSV = os.getenv('CATEGORIZE_CSV')
FILTERED_DATA_CSV = os.getenv('FILTERED_DATA_CSV')
OUTPUT_PATH = os.getenv('OUTPUT_PATH')

# ----------------------------------------
# ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£é–¢æ•°
# ----------------------------------------

def extract_number_from_title(title):
    """ã‚¿ã‚¤ãƒˆãƒ«ã®æœ«å°¾ã‹ã‚‰æ•°å­—ã‚’æŠ½å‡ºï¼ˆè¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° -1ï¼‰"""
    match = re.search(r'(\d+)$', title)
    return int(match.group(1)) if match else -1

def normalize_playlist_id(pid):
    """URLã‹ã‚‰playlist IDã‚’æŠ½å‡ºã€ã™ã§ã«IDå½¢å¼ãªã‚‰ãã®ã¾ã¾"""
    return pid.split('list=')[1] if isinstance(pid, str) and 'list=' in pid else pid

def to_playlist_url(playlist_id):
    """playlist IDã‹ã‚‰URLã‚’ç”Ÿæˆ"""
    return f"https://www.youtube.com/playlist?list={playlist_id}"

# ----------------------------------------
# YouTube API æ“ä½œ
# ----------------------------------------

def get_playlists(api_key, channel_id):
    """YouTube APIã‹ã‚‰ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆä¸€è¦§ã‚’å–å¾—"""
    youtube = build('youtube', 'v3', developerKey=api_key)
    playlists = []
    nextPageToken = None

    while True:
        request = youtube.playlists().list(
            part='snippet,contentDetails',
            channelId=channel_id,
            maxResults=50,
            pageToken=nextPageToken
        )
        response = request.execute()

        for item in response['items']:
            playlists.append({
                'title': item['snippet']['title'],
                'playlist_id': item['id'],
                'video_count': item['contentDetails']['itemCount']
            })

        nextPageToken = response.get('nextPageToken')
        if not nextPageToken:
            break

    return playlists

# ----------------------------------------
# CSVæ“ä½œ
# ----------------------------------------

def update_csv_counts(csv_path, youtube_playlists):
    """CSVå†…ã®countåˆ—ã‚’YouTubeä¸Šã®å®Ÿæ•°ã§æ›´æ–°"""
    df = pd.read_csv(csv_path)
    df['playlist_id'] = df['url'].apply(normalize_playlist_id)
    playlist_map = {p['playlist_id']: p['video_count'] for p in youtube_playlists}

    def update_count(row):
        return playlist_map.get(row['playlist_id'], row['count'])

    df['count'] = df.apply(update_count, axis=1)
    df.drop(columns=['playlist_id'], inplace=True)
    df.to_csv(csv_path, index=False)

    print('âœ… count ã‚’æ›´æ–°ã—ã¾ã—ãŸ')

# ----------------------------------------
# ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ»æ¯”è¼ƒå‡¦ç†
# ----------------------------------------

def fetch_playlist_data(playlist):
    youtube = build('youtube', 'v3', developerKey=API_KEY)
    playlist_id = playlist['playlist_id']
    playlist_title = playlist['title']

    videos = []
    nextPageToken = None
    while True:
        request = youtube.playlistItems().list(
            part='snippet',
            playlistId=playlist_id,
            maxResults=50,
            pageToken=nextPageToken
        )
        response = request.execute()
        time.sleep(1)

        for item in response['items']:
            snippet = item['snippet']
            video_id = snippet['resourceId']['videoId']
            video_title = snippet['title']
            channel_title = snippet.get('videoOwnerChannelTitle', snippet.get('channelTitle', ''))
            published_at = snippet['publishedAt']
            video_url = f'https://www.youtube.com/watch?v={video_id}'

            videos.append({
                'title': video_title,
                'channel': channel_title,
                'date': published_at,
                'url': video_url,
                'playlist': playlist_title
            })

        nextPageToken = response.get('nextPageToken')
        if not nextPageToken:
            break

    if os.path.exists(MAIN_DATA_CSV):
        df_existing = pd.read_csv(MAIN_DATA_CSV)
        max_id = df_existing['id'].max() if not df_existing.empty else 0
    else:
        df_existing = pd.DataFrame()
        max_id = 0

    df_new = pd.DataFrame(videos)
    df_new.insert(0, 'id', range(max_id + 1, max_id + 1 + len(df_new)))

    df_combined = pd.concat([df_existing, df_new], ignore_index=True) if not df_existing.empty else df_new
    df_combined.to_csv(MAIN_DATA_CSV, index=False)

    print(f"âœ… ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆã€{playlist_title}ã€ã®å‹•ç”»ãƒ‡ãƒ¼ã‚¿ã‚’ {MAIN_DATA_CSV} ã«è¿½è¨˜ã—ã¾ã—ãŸï¼ˆ{len(df_new)}ä»¶ï¼‰")

    if os.path.exists(PLAYLISTS_CSV):
        df_playlists = pd.read_csv(PLAYLISTS_CSV)
        df_playlists['playlist_id'] = df_playlists['playlist_id'].apply(normalize_playlist_id)
    else:
        df_playlists = pd.DataFrame(columns=['title', 'playlist_id', 'video_count'])

    video_count = len(videos)

    if playlist_id in df_playlists['playlist_id'].values:
        df_playlists.loc[df_playlists['playlist_id'] == playlist_id, ['title', 'video_count']] = [playlist_title, video_count]
    else:
        df_playlists = pd.concat([df_playlists, pd.DataFrame([{
            'title': playlist_title,
            'playlist_id': playlist_id,
            'video_count': video_count
        }])], ignore_index=True)

    # âœ… ä¿å­˜å‰ã« playlist_id ã‚’ URLå½¢å¼ã«æˆ»ã™
    df_playlists['playlist_id'] = df_playlists['playlist_id'].apply(to_playlist_url)
    df_playlists.to_csv(PLAYLISTS_CSV, index=False)

    print(f"âœ… ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆæƒ…å ±ã‚’ {PLAYLISTS_CSV} ã«æ›´æ–°ã—ã¾ã—ãŸ")

def identify_and_fetch_target_playlists(youtube_playlists, csv_path):
    df = pd.read_csv(csv_path)
    df['playlist_id'] = df['playlist_id'].apply(normalize_playlist_id)
    csv_map = df.set_index('playlist_id').to_dict(orient='index')

    for playlist in youtube_playlists:
        pid = playlist['playlist_id']
        youtube_count = playlist['video_count']
        csv_entry = csv_map.get(pid)

        if csv_entry is None:
            print(f"ğŸ†• CSVã«å­˜åœ¨ã—ãªã„ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {playlist['title']}")
            fetch_playlist_data(playlist)
        elif youtube_count != csv_entry['video_count']:
            print(f"âš ï¸ countä¸ä¸€è‡´: {playlist['title']}ï¼ˆCSV: {csv_entry['video_count']} â†’ YouTube: {youtube_count}ï¼‰")
            fetch_playlist_data(playlist)

def check_csv_latest_playlist(youtube_playlists, csv_path):
    df = pd.read_csv(csv_path)
    df['playlist_id'] = df['playlist_id'].apply(normalize_playlist_id)
    df['number'] = df['title'].apply(extract_number_from_title)
    latest_row = df.loc[df['number'].idxmax()]
    latest_title = latest_row['title']
    csv_count = latest_row['video_count']

    print(f"ğŸ—‚ï¸ CSVä¸Šã®æœ€æ–°ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆ: {latest_title}ï¼ˆcount: {csv_count}ï¼‰")

    match = next((p for p in youtube_playlists if p['title'] == latest_title), None)
    if not match:
        print('âš ï¸ YouTubeä¸Šã«åŒåã®ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“')
        return

    youtube_count = match['video_count']
    if csv_count == youtube_count:
        print('âœ… CSVã¨YouTubeã®å‹•ç”»æ•°ã¯ä¸€è‡´ã—ã¦ã„ã¾ã™')
    else:
        print(f'âŒ ä¸ä¸€è‡´ã§ã™ï¼ˆCSV: {csv_count}, YouTube: {youtube_count}ï¼‰')

def clean_and_sort_main_data():
    if not os.path.exists(MAIN_DATA_CSV):
        print(f"âŒ {MAIN_DATA_CSV} ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    df = pd.read_csv(MAIN_DATA_CSV)
    before_count = len(df)
    df = df.drop_duplicates(subset='url')
    df = df.sort_values(by='date', ascending=False).reset_index(drop=True)

    if 'id' in df.columns:
        df = df.drop(columns=['id'])

    df.insert(0, 'id', range(1, len(df) + 1))
    df.to_csv(MAIN_DATA_CSV, index=False)
    after_count = len(df)

    print(f"ğŸ§¹ main-data.csv ã‚’æ•´ç†ã—ã¾ã—ãŸï¼ˆ{before_count} â†’ {after_count}ä»¶ã€æœ€æ–°é †ãƒ»é‡è¤‡å‰Šé™¤ï¼‰")

def filter_checked_channels(output_csv=FILTERED_DATA_CSV, verbose=True):
    if not os.path.exists(MAIN_DATA_CSV) or not os.path.exists(CATEGORIZE_CSV):
        print("âŒ å¿…è¦ãªCSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
        return

    df_main = pd.read_csv(MAIN_DATA_CSV)
    df_categorize = pd.read_csv(CATEGORIZE_CSV)
    checked_channels = df_categorize[df_categorize['check'] == 1]['channel'].unique()
    df_filtered = df_main[df_main['channel'].isin(checked_channels)]
    df_filtered.to_csv(output_csv, index=False)

    if verbose:
        print(f"âœ… check=1 ã®ãƒãƒ£ãƒ³ãƒãƒ«ã®å‹•ç”»ã‚’ {output_csv} ã«ä¿å­˜ã—ã¾ã—ãŸï¼ˆ{len(df_filtered)}ä»¶ï¼‰")

    return df_filtered

# ----------------------------------------
# ãƒ¡ã‚¤ãƒ³å‡¦ç†
# ----------------------------------------

def main():
    print('â–¶ï¸ ãƒ—ãƒ¬ã‚¤ãƒªã‚¹ãƒˆå–å¾—ä¸­...')
    playlists = get_playlists(API_KEY, CHANNEL_ID)

    print('ğŸ” CSVã¨ã®æ¯”è¼ƒãƒ»ãƒ‡ãƒ¼ã‚¿å–å¾—å¯¾è±¡ã‚’åˆ¤å®šä¸­...')
    identify_and_fetch_target_playlists(playlists, PLAYLISTS_CSV)

    clean_and_sort_main_data()
    filter_checked_channels()

    try:
        shutil.copy(FILTERED_DATA_CSV, OUTPUT_PATH)
        print(f"âœ… {FILTERED_DATA_CSV} ã‚’ {OUTPUT_PATH} ã«ã‚³ãƒ”ãƒ¼ã—ã¾ã—ãŸã€‚")
    except Exception as e:
        print(f"âŒ ã‚³ãƒ”ãƒ¼ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")

if __name__ == '__main__':
    main()
